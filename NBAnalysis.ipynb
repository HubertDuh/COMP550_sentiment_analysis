{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7e2de0329b050e4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:29:39.456773Z",
     "start_time": "2023-12-16T10:29:38.942413Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import csv\n",
    "import sklearn.feature_extraction\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from scipy import sparse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed28d14f4593b529",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Bernoulli NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e29c9527e061faa5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T05:06:57.999813Z",
     "start_time": "2023-12-16T05:06:57.656603Z"
    }
   },
   "outputs": [],
   "source": [
    "class BernoulliNaiveBayes(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.class_log_prior_ = None\n",
    "        self.feature_log_prob_ = None\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        unique_y = np.unique(y)\n",
    "        self.classes_ = unique_y\n",
    "        count_sample = X.shape[0]\n",
    "        self.class_log_prior_ = np.log([np.sum(y == yi) / count_sample for yi in unique_y])\n",
    "\n",
    "        self.feature_log_prob_ = np.array([\n",
    "         np.log((X[y == yi].sum(axis=0) + self.alpha)\n",
    "                (np.sum(y == yi) + 2 * self.alpha))\n",
    "            for yi in unique_y\n",
    "        ])\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Convert to dense array if X is a sparse matrix\n",
    "        if sparse.issparse(X):\n",
    "            X = X.toarray()\n",
    "\n",
    "        # Calculate log probabilities for each class\n",
    "        # Ensure that the operations are performed correctly on matrices/arrays\n",
    "        log_probs = X.dot(self.feature_log_prob_.T) + self.class_log_prior_[np.newaxis, :]\n",
    "\n",
    "        # Select the class with the highest log probability\n",
    "        return self.classes_[np.argmax(log_probs, axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2932b706b14c6797",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b80843d8093ea10",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T05:06:58.048636Z",
     "start_time": "2023-12-16T05:06:57.671994Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultinomialNaiveBayes(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.class_log_prior_ = None\n",
    "        self.feature_log_prob_ = None\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        unique_y = np.unique(y)\n",
    "        self.classes_ = unique_y\n",
    "        count_sample = X.shape[0]\n",
    "        self.class_log_prior_ = np.log([np.sum(y == yi) / count_sample for yi in unique_y])\n",
    "\n",
    "        self.feature_log_prob_ = np.array([\n",
    "            np.log((X[y == yi].sum(axis=0) + self.alpha) / (X[y == yi].sum() + self.alpha * X.shape[1]))\n",
    "            for yi in unique_y\n",
    "        ])\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.classes_[np.argmax(\n",
    "            self.class_log_prior_ + X_test.dot(self.feature_log_prob_.T))\n",
    "                         ] for X_test in X])\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return np.array([(self.class_log_prior_ + X_test.dot(self.feature_log_prob_.T)).exp()\n",
    "                         for X_test in X])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9e783080af6bd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db97ed4f9673d52f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T05:06:58.070420Z",
     "start_time": "2023-12-16T05:06:57.683366Z"
    }
   },
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, epsilon=1e-9):\n",
    "        self.epsilon = epsilon\n",
    "        self.means_ = None\n",
    "        self.variances_ = None\n",
    "        self.class_prior_ = None\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_features = X.shape[1]\n",
    "        n_classes = len(self.classes_)\n",
    "\n",
    "        self.means_ = np.zeros((n_classes, n_features))\n",
    "        self.variances_ = np.zeros((n_classes, n_features))\n",
    "        self.class_prior_ = np.zeros(n_classes)\n",
    "\n",
    "        for idx, c in enumerate(self.classes_):\n",
    "            X_c = X[y == c]\n",
    "            self.means_[idx, :] = X_c.mean(axis=0)\n",
    "            # Add epsilon for variance smoothing\n",
    "            self.variances_[idx, :] = X_c.var(axis=0) + self.epsilon\n",
    "            self.class_prior_[idx] = X_c.shape[0] / float(X.shape[0])\n",
    "        return self\n",
    "\n",
    "    def _calculate_log_likelihood(self, X, class_idx):\n",
    "        mean = self.means_[class_idx]\n",
    "        variance = self.variances_[class_idx]\n",
    "        exponent = np.exp(-(X - mean) ** 2 / (2 * variance))\n",
    "        return np.sum(-0.5 * np.log(2 * np.pi * variance) - exponent / (2 * variance), axis=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        log_likelihoods = np.array([self._calculate_log_likelihood(X, i) for i in range(len(self.classes_))]).T\n",
    "        log_prior = np.log(self.class_prior_)\n",
    "        log_posterior = log_likelihoods + log_prior\n",
    "        return self.classes_[np.argmax(log_posterior, axis=1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cce8965aa463991",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# English Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "811561f8066a8afa",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T05:06:58.100948Z",
     "start_time": "2023-12-16T05:06:57.710788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n@InProceedings{maas-EtAl:2011:ACL-HLT2011,\\n  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\\n  title     = {Learning Word Vectors for Sentiment Analysis},\\n  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\\n  month     = {June},\\n  year      = {2011},\\n  address   = {Portland, Oregon, USA},\\n  publisher = {Association for Computational Linguistics},\\n  pages     = {142--150},\\n  url       = {http://www.aclweb.org/anthology/P11-1015}\\n}\\n\\n@data{yfwt-wr77-20,\\ndoi = {10.21227/yfwt-wr77},\\nurl = {https://dx.doi.org/10.21227/yfwt-wr77},\\nauthor = {Tan, Songbo},\\npublisher = {IEEE Dataport},\\ntitle = {ChnSentiCorp},\\nyear = {2020} \\n}\\n\\n@online{allocine_dataset,\\n  title        = {Allocine Dataset},\\n  author       = {{Th√©ophile Blard}},\\n  year         = {Year the dataset was accessed},\\n  url          = {https://github.com/TheophileBlard/french-sentiment-analysis-with-bert/blob/master/allocine_dataset/data.tar.bz2},\\n  note         = {Accessed: Date you accessed the dataset},\\n}\\n@misc{stopwords_zh_2023,\\n  author = {{stopwords-iso}},\\n  title = {Chinese Stopwords List},\\n  year = {2023},\\n  url = {https://github.com/stopwords-iso/stopwords-zh/blob/master/stopwords-zh.txt},\\n  note = {GitHub repository}\\n}\\n\\n'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
    "  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
    "  title     = {Learning Word Vectors for Sentiment Analysis},\n",
    "  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
    "  month     = {June},\n",
    "  year      = {2011},\n",
    "  address   = {Portland, Oregon, USA},\n",
    "  publisher = {Association for Computational Linguistics},\n",
    "  pages     = {142--150},\n",
    "  url       = {http://www.aclweb.org/anthology/P11-1015}\n",
    "}\n",
    "\n",
    "@data{yfwt-wr77-20,\n",
    "doi = {10.21227/yfwt-wr77},\n",
    "url = {https://dx.doi.org/10.21227/yfwt-wr77},\n",
    "author = {Tan, Songbo},\n",
    "publisher = {IEEE Dataport},\n",
    "title = {ChnSentiCorp},\n",
    "year = {2020} \n",
    "}\n",
    "\n",
    "@online{allocine_dataset,\n",
    "  title        = {Allocine Dataset},\n",
    "  author       = {{Th√©ophile Blard}},\n",
    "  year         = {Year the dataset was accessed},\n",
    "  url          = {https://github.com/TheophileBlard/french-sentiment-analysis-with-bert/blob/master/allocine_dataset/data.tar.bz2},\n",
    "  note         = {Accessed: Date you accessed the dataset},\n",
    "}\n",
    "@misc{stopwords_zh_2023,\n",
    "  author = {{stopwords-iso}},\n",
    "  title = {Chinese Stopwords List},\n",
    "  year = {2023},\n",
    "  url = {https://github.com/stopwords-iso/stopwords-zh/blob/master/stopwords-zh.txt},\n",
    "  note = {GitHub repository}\n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "152049939d800b5b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T05:09:06.538793Z",
     "start_time": "2023-12-16T05:06:57.725839Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/english/aclImdb/train.tsv\", delimiter='\\t', encoding='utf-8')\n",
    "test_df = pd.read_csv(\"data/english/aclImdb/train.tsv\", delimiter='\\t', encoding='utf-8')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "train_df['text_a'] = train_df['text_a'].apply(clean_text)\n",
    "test_df['text_a'] = test_df['text_a'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99c29fe71d9aaea",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## English Bernoulli NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ede8b721778e353e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T05:09:13.415694Z",
     "start_time": "2023-12-16T05:09:06.544715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.5}\n",
      "Best Cross-Validated Score: 0.8452\n",
      "Validation Set Accuracy: 0.8472\n",
      "Validation Set F1 Score: 0.8394957983193277\n",
      "Test Set Accuracy: 0.90324\n",
      "Test Set F1 Score: 0.8992796768955323\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "X = vectorizer.fit_transform(train_df['text_a'])\n",
    "y = train_df['label']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {'alpha': [0.1, 0.5, 1, 2, 5]}\n",
    "grid_search = GridSearchCV(BernoulliNB(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validated Score:\", grid_search.best_score_)\n",
    "\n",
    "best_bernoulli_model = grid_search.best_estimator_\n",
    "\n",
    "y_val_pred = best_bernoulli_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, y_val_pred)\n",
    "print(f\"Validation Set Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation Set F1 Score: {val_f1}\")\n",
    "\n",
    "\n",
    "X_test = vectorizer.transform(test_df['text_a'])\n",
    "y_test = test_df['label']\n",
    "y_test_pred = best_bernoulli_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Set F1 Score: {test_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3468327f8d1e71a7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## English Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13a9d2862413ccbe",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T05:09:19.553676Z",
     "start_time": "2023-12-16T05:09:13.408295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 5}\n",
      "Best Cross-Validated Score: 0.8572\n",
      "Validation Set Accuracy: 0.8566\n",
      "Validation Set F1 Score: 0.8532842234499692\n",
      "Test Set Accuracy: 0.88872\n",
      "Test Set F1 Score: 0.8866987048953328\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = CountVectorizer(binary=False)  \n",
    "X = vectorizer.fit_transform(train_df['text_a'])\n",
    "y = train_df['label']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {'alpha': [0.1, 0.5, 1, 2, 5]}\n",
    "grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validated Score:\", grid_search.best_score_)\n",
    "\n",
    "best_multinomial_model = grid_search.best_estimator_\n",
    "y_val_pred = best_multinomial_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation Set Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation Set F1 Score: {val_f1}\")\n",
    "\n",
    "\n",
    "X_test = vectorizer.transform(test_df['text_a'])\n",
    "y_test = test_df['label']\n",
    "y_test_pred = best_multinomial_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Set F1 Score: {test_f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a85dc2bc6b1cb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## English Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6203f5f581269e7c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T05:29:02.861517Z",
     "start_time": "2023-12-16T05:09:19.551664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Accuracy: 0.6374\n",
      "Validation Set F1 Score: 0.5751113194281696\n",
      "Test Set Accuracy: 0.83456\n",
      "Test Set F1 Score: 0.8118289353958145\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(train_df['text_a']).toarray()\n",
    "y = train_df['label']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = make_pipeline(StandardScaler(), GaussianNB())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation Set Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation Set F1 Score: {val_f1}\")\n",
    "\n",
    "\n",
    "\n",
    "X_test = vectorizer.transform(test_df['text_a']).toarray() \n",
    "y_test = test_df['label']\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Set F1 Score: {test_f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1432ddd5236b5c12",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# French Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef88efb140d6ff2d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T05:34:33.398299Z",
     "start_time": "2023-12-16T05:29:02.945288Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/french/data/train.tsv\", delimiter='\\t', encoding='utf-8')\n",
    "test_df = pd.read_csv(\"data/french/data/train.tsv\", delimiter='\\t', encoding='utf-8')\n",
    "val_df = pd.read_csv(\"data/french/data/val.tsv\", delimiter='\\t', encoding='utf-8')\n",
    "\n",
    "stop_words = set(stopwords.words('french'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "train_df['text_a'] = train_df['text_a'].apply(clean_text)\n",
    "test_df['text_a'] = test_df['text_a'].apply(clean_text)\n",
    "val_df['text_a'] = val_df['text_a'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7dff2fd38a3339",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## French Bernoulli NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5069c2a3ada050ec",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T05:34:57.073816Z",
     "start_time": "2023-12-16T05:34:33.421684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 5}\n",
      "Best Cross-Validated Score: 0.858967410405097\n",
      "Validation Set Accuracy: 0.866870122073244\n",
      "Validation Set F1 Score: 0.8550100800958971\n",
      "Test Set Accuracy: 0.8717640954470721\n",
      "Test Set F1 Score: 0.864569372462285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "X_train = vectorizer.fit_transform(train_df['text_a'])\n",
    "y_train = train_df['label']\n",
    "\n",
    "X_val = vectorizer.transform(val_df['text_a'])\n",
    "y_val = val_df['label']\n",
    "\n",
    "param_grid = {'alpha': [0.1, 0.5, 1, 2, 5]}\n",
    "grid_search = GridSearchCV(BernoulliNB(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validated Score:\", grid_search.best_score_)\n",
    "\n",
    "best_bernoulli_model = grid_search.best_estimator_\n",
    "y_val_pred = best_bernoulli_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation Set Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation Set F1 Score: {val_f1}\")\n",
    "\n",
    "\n",
    "X_test = vectorizer.transform(test_df['text_a'])\n",
    "y_test = test_df['label']\n",
    "y_test_pred = best_bernoulli_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Set F1 Score: {test_f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0f2c060f5f04bf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## French Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b88275c535cf8e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T05:35:18.209265Z",
     "start_time": "2023-12-16T05:34:57.129241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 5}\n",
      "Best Cross-Validated Score: 0.8978201404194077\n",
      "Validation Set Accuracy: 0.9021412847708625\n",
      "Validation Set F1 Score: 0.8997539975399754\n",
      "Test Set Accuracy: 0.911110694348068\n",
      "Test Set F1 Score: 0.911869890480411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = CountVectorizer(binary=False)  \n",
    "X_train = vectorizer.fit_transform(train_df['text_a'])\n",
    "y_train = train_df['label']\n",
    "\n",
    "X_val = vectorizer.transform(val_df['text_a'])\n",
    "y_val = val_df['label']\n",
    "\n",
    "param_grid = {'alpha': [0.1, 0.5, 1, 2, 5]}\n",
    "grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validated Score:\", grid_search.best_score_)\n",
    "\n",
    "best_multinomial_model = grid_search.best_estimator_\n",
    "y_val_pred = best_multinomial_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation Set Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation Set F1 Score: {val_f1}\")\n",
    "\n",
    "\n",
    "X_test = vectorizer.transform(test_df['text_a'])\n",
    "y_test = test_df['label']\n",
    "y_test_pred = best_multinomial_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Set F1 Score: {test_f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2812c744fb87ee2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## French Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7535225dd04a367d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:30:33.674460Z",
     "start_time": "2023-12-16T10:30:19.045536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Accuracy: 0.73\n",
      "Validation Set F1 Score: 0.696060037523452\n",
      "Test Set Accuracy: 0.7291666666666666\n",
      "Test Set F1 Score: 0.7037374658158614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_df['text_a']).toarray()\n",
    "y_train = train_df['label']\n",
    "\n",
    "X_val = vectorizer.transform(val_df['text_a']).toarray()\n",
    "y_val = val_df['label']\n",
    "\n",
    "model = make_pipeline(StandardScaler(), GaussianNB())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation Set Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation Set F1 Score: {val_f1}\")\n",
    "\n",
    "\n",
    "\n",
    "X_test = vectorizer.transform(test_df['text_a']).toarray() \n",
    "y_test = test_df['label']\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Set F1 Score: {test_f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3558e60886e46511",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Chinese Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c704b5d03202845e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:29:26.909974Z",
     "start_time": "2023-12-16T10:29:21.337584Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/8y/pwclkfq17dgfr91dw_mc9flr0000gn/T/jieba.cache\n",
      "Loading model cost 0.637 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"data/chinese/chnsenticorp-main/train.tsv\", delimiter='\\t', encoding='utf-8')\n",
    "test_df = pd.read_csv(\"data/chinese/chnsenticorp-main/test.tsv\", delimiter='\\t', encoding='utf-8')\n",
    "val_df = pd.read_csv(\"data/chinese/chnsenticorp-main/dev.tsv\", delimiter='\\t', encoding='utf-8')\n",
    "\n",
    "def load_stop_words(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        stop_words = set(file.read().splitlines())\n",
    "    return stop_words\n",
    "\n",
    "stop_words = load_stop_words('data/chinese/stopwords-zh.txt')  # Replace with your stop words list\n",
    "\n",
    "def clean_text(text):\n",
    "    words = jieba.cut(text)\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "train_df['text_a'] = train_df['text_a'].apply(clean_text)\n",
    "test_df['text_a'] = test_df['text_a'].apply(clean_text)\n",
    "val_df['text_a'] = val_df['text_a'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cec9974b896f9e8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Chinese Bernoulli NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7bc388cd07aac14",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:29:46.080939Z",
     "start_time": "2023-12-16T10:29:45.372878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.5}\n",
      "Best Cross-Validated Score: 0.849769081614666\n",
      "Validation Set Accuracy: 0.8466666666666667\n",
      "Validation Set F1 Score: 0.8327272727272728\n",
      "Test Set Accuracy: 0.865\n",
      "Test Set F1 Score: 0.8617747440273037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "X_train = vectorizer.fit_transform(train_df['text_a'])\n",
    "y_train = train_df['label']\n",
    "\n",
    "X_val = vectorizer.transform(val_df['text_a'])\n",
    "y_val = val_df['label']\n",
    "\n",
    "param_grid = {'alpha': [0.1, 0.5, 1, 2, 5]}\n",
    "grid_search = GridSearchCV(BernoulliNB(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validated Score:\", grid_search.best_score_)\n",
    "\n",
    "best_bernoulli_model = grid_search.best_estimator_\n",
    "y_val_pred = best_bernoulli_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation Set Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation Set F1 Score: {val_f1}\")\n",
    "\n",
    "\n",
    "X_test = vectorizer.transform(test_df['text_a'])\n",
    "y_test = test_df['label']\n",
    "y_test_pred = best_bernoulli_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Set F1 Score: {test_f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0559f24030e3e3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Chinese Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dad38aff6a26d032",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:29:52.061788Z",
     "start_time": "2023-12-16T10:29:51.532242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.1}\n",
      "Best Cross-Validated Score: 0.837742084868258\n",
      "Validation Set Accuracy: 0.8475\n",
      "Validation Set F1 Score: 0.8437233134073442\n",
      "Test Set Accuracy: 0.8441666666666666\n",
      "Test Set F1 Score: 0.8495575221238939\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = CountVectorizer(binary=False)  \n",
    "X_train = vectorizer.fit_transform(train_df['text_a'])\n",
    "y_train = train_df['label']\n",
    "\n",
    "X_val = vectorizer.transform(val_df['text_a'])\n",
    "y_val = val_df['label']\n",
    "\n",
    "param_grid = {'alpha': [0.1, 0.5, 1, 2, 5]}\n",
    "grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validated Score:\", grid_search.best_score_)\n",
    "\n",
    "best_multinomial_model = grid_search.best_estimator_\n",
    "y_val_pred = best_multinomial_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation Set Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation Set F1 Score: {val_f1}\")\n",
    "\n",
    "X_test = vectorizer.transform(test_df['text_a'])\n",
    "y_test = test_df['label']\n",
    "y_test_pred = best_multinomial_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Set F1 Score: {test_f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d4deb562cbcd8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Chinese Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "152fed16978bbdaa",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T10:30:10.791230Z",
     "start_time": "2023-12-16T10:29:55.735599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Accuracy: 0.73\n",
      "Validation Set F1 Score: 0.696060037523452\n",
      "Test Set Accuracy: 0.7291666666666666\n",
      "Test Set F1 Score: 0.7037374658158614\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_df['text_a']).toarray()\n",
    "y_train = train_df['label']\n",
    "\n",
    "X_val = vectorizer.transform(val_df['text_a']).toarray()\n",
    "y_val = val_df['label']\n",
    "\n",
    "model = make_pipeline(StandardScaler(), GaussianNB())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation Set Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation Set F1 Score: {val_f1}\")\n",
    "\n",
    "\n",
    "\n",
    "X_test = vectorizer.transform(test_df['text_a']).toarray() \n",
    "y_test = test_df['label']\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Set Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Set F1 Score: {test_f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83290b42a059725e",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
